{"cells":[{"cell_type":"markdown","metadata":{"id":"IwLYi_u7CliM"},"source":["# Setup environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31782,"status":"ok","timestamp":1697592861424,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"vYUCzUa3Gkps","outputId":"c545f413-969d-4df3-fdfb-740b5a2fcc4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from pathlib import Path\n","import sys\n","\n","if 'google.colab' in str(get_ipython()):\n","    from google.colab import drive  # Import Google Drive mounting utility\n","    drive.mount('/content/drive')  # Mount Google Drive\n","\n","    # REPLACE WITH YOUR FOLDER\n","\n","    base_folder = Path('/content/drive/MyDrive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data')\n","\n","    data_folder =  Path('/content')\n","\n","    !pip install pytorch-lightning==2.0.9 -qq\n","    !pip install torchmetrics -U -qq\n","    !pip install fastdownload -U -qq\n","    !pip install fastai -U -qq\n","    !pip install wandb -U -qq\n","\n","else:\n","    # Set base folder path for storing files on local machine\n","    # REPLACE WITH YOUR FOLDER\n","    # FILL THIS ONLY IF YOU ARE RUNNING ON A LOCAL MACHINE\n","    print('Path is /Users/harikrishnadev/Library/CloudStorage/GoogleDrive-harikrish0607@gmail.com/My Drive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data')\n","\n","    base_folder = Path('/Users/harikrishnadev/Library/CloudStorage/GoogleDrive-harikrish0607@gmail.com/My Drive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data')\n","    data_folder = base_folder\n","    !pip install pytorch-lightning==2.0.9 -qq\n","    !pip install torchmetrics -U -qq\n","    !pip install fastdownload -U -qq\n","    !pip install fastai -U -qq\n","    !pip install wandb -U -qq"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"16KuaJuIG0v0","executionInfo":{"status":"ok","timestamp":1697592861796,"user_tz":300,"elapsed":4,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["# custom_function_folder = base_folder/'data/custom-functions/fall_2023'\n","# sys.path.append(str(custom_function_folder))\n","# model_folder = base_folder/'data/models/dl_fall_2023/dog_breed/oct-9'\n","# model_folder.mkdir(parents=True, exist_ok=True)\n","# project_folder = base_folder/'data/imagenette2'\n","# kaggle_api_folder = base_folder/'data/.kaggle'\n","\n","\n","# Change the custom_function_folder to folder in your Google drive folder\n","# Make sure you keep the mlp_skip_two_layer.py and shared_utils.py files\n","from pathlib import Path\n","import sys\n","\n","# Determine the storage location based on the execution environment\n","# If running on Google Colab, use Google Drive as storage\n","if 'google.colab' in str(get_ipython()):\n","    custom_function_folder = Path('/content/drive/MyDrive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Custom_files') # Your Google Drive\n","\n","    sys.path.append(str(custom_function_folder))\n","    model_folder = Path('/content/drive/MyDrive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data') # Google drive folder where you want to save model and logs\n","    model_folder.mkdir(parents=True, exist_ok=True)\n","    project_folder = base_folder/'data/imagenette2'\n","    kaggle_api_folder = base_folder/'data/.kaggle'\n","\n","# If running locally, specify a different path\n","else:\n","    # Set base folder path for storing files on local machine\n","    # REPLACE WITH YOUR FOLDER\n","    # FILL THIS ONLY IF YOU ARE RUNNING ON A LOCAL MACHINE\n","    print('Path is /Users/harikrishnadev/Library/CloudStorage/GoogleDrive-harikrish0607@gmail.com/My Drive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Custom_files')\n","    custom_function_folder = Path('/Users/harikrishnadev/Library/CloudStorage/GoogleDrive-harikrish0607@gmail.com/My Drive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Custom_files') # Your Google Drive\n","\n","    sys.path.append(str(custom_function_folder))\n","    model_folder = Path('/Users/harikrishnadev/Library/CloudStorage/GoogleDrive-harikrish0607@gmail.com/My Drive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data') # Google drive folder where you want to save model and logs\n","    model_folder.mkdir(parents=True, exist_ok=True)\n","    project_folder = base_folder/'data/imagenette2'\n","    kaggle_api_folder = base_folder/'data/.kaggle'\n","    # project_folder = Path('/Users/harikrishnadev/Library/CloudStorage/GoogleDrive-harikrish0607@gmail.com/My Drive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3u9XrlcJCliP","executionInfo":{"status":"ok","timestamp":1697592869628,"user_tz":300,"elapsed":7835,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["# import Libraries\n","import yaml\n","\n","import torch\n","import torchmetrics\n","from torchvision import transforms\n","import pytorch_lightning as pl\n","from pytorch_lightning import seed_everything\n","from pytorch_lightning.tuner import Tuner\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import CSVLogger, WandbLogger\n","import wandb\n","import gc\n","\n","from data_module_imagenette2 import ImagenetteDataModule\n","from multiclass_lightning_module_v0 import MultiClassLightningModule\n","from model_two_layer_bn import TwoLayerMLPBN\n","from shared_utils import  plot_losses_acc"]},{"cell_type":"markdown","metadata":{"id":"PJQusXlFCliQ"},"source":["# Function to load the model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"inWoshD0CliQ","executionInfo":{"status":"ok","timestamp":1697592869630,"user_tz":300,"elapsed":8,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["# Function to load the model\n","def load_model(config):\n","    model = TwoLayerMLPBN(**config)\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"UB2P4f6PCliQ"},"source":["# Functions for Transformations"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"e6YhWMJQCliQ","executionInfo":{"status":"ok","timestamp":1697592869630,"user_tz":300,"elapsed":7,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def get_train_transforms(resize_height, resize_width, normalize_mean, normalize_std):\n","\n","    return transforms.Compose(\n","        [\n","            transforms.Resize((resize_height, resize_width)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(normalize_mean, normalize_std),\n","        ]\n","    )\n","\n","def get_test_transforms(resize_height, resize_width, normalize_mean, normalize_std):\n","\n","    return transforms.Compose(\n","        [\n","            transforms.Resize((resize_height, resize_width)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(normalize_mean, normalize_std),\n","        ]\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"krRrWALXCliQ"},"source":["# Function to load DataModule"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TXBzfyHQCliR","executionInfo":{"status":"ok","timestamp":1697592869630,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def load_datamodule(config, data_folder):\n","    # Fetch the correct transform function based on config and pass the appropriate arguments\n","    train_transform = get_train_transforms(**config['train_transform'])\n","    test_transform = get_test_transforms(**config['test_transform'])\n","    dm = ImagenetteDataModule(\n","        data_dir=data_folder,\n","        train_transform=train_transform,\n","        test_transform=test_transform,\n","        **config['data_module']\n","    )\n","    return dm\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZkgKbM7-CliR"},"source":["# Function to load LightningModule"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"tbqknSr6CliR","executionInfo":{"status":"ok","timestamp":1697592869630,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def load_lightning_module(config, model):\n","    optimizer_cls = eval(config['optimizer_cls'])\n","    loss_fn = eval(config['loss_fn'])()  # directly instantiate the loss function\n","    metric_cls = eval(config['metric_cls'])\n","\n","    # If scheduler is defined, convert its string to class as well\n","    if config.get('scheduler_cls'):\n","        scheduler_cls = eval(config['scheduler_cls'])\n","        scheduler_options = config['scheduler_options']\n","        scheduler_params =   config['scheduler_params']\n","    else:\n","        scheduler_cls = None\n","\n","    lightning_module = MultiClassLightningModule(model=model,\n","                                                 optimizer_cls=optimizer_cls,\n","                                                 loss_fn=loss_fn,\n","                                                 metric_cls=metric_cls,\n","                                                 scheduler_cls=scheduler_cls,\n","                                                 scheduler_options=scheduler_options,\n","                                                 scheduler_params=scheduler_params,\n","                                                 **config['others']\n",")\n","    return lightning_module\n"]},{"cell_type":"markdown","metadata":{"id":"KZTHYSFDCliR"},"source":["# Function to load the Trainer"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"jBYX5HRJCliR","executionInfo":{"status":"ok","timestamp":1697592869630,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def load_trainer(model, trainer_config, cl_config, batch_size, model_folder,  logging=False, checkpointing=True, early_stopping=False):\n","\n","    lr_monitor = LearningRateMonitor(**cl_config['lr_monitor'])\n","    callbacks = [lr_monitor]\n","    if checkpointing:\n","        model_checkpoint_callback = ModelCheckpoint(dirpath=model_folder/cl_config['log_dir'],\n","                                                **cl_config['model_checkpoint'])\n","        callbacks.append(model_checkpoint_callback)\n","\n","    if early_stopping:\n","        early_stop_callback = EarlyStopping(**cl_config['early_stopping'] )\n","        callbacks.append(early_stop_callback)\n","\n","    if logging:\n","        # For WandB logger:\n","        wandb_logger = WandbLogger(project=cl_config['wandb']['project'], name=cl_config['wandb']['name'], save_dir=model_folder/cl_config['log_dir'])\n","        wandb_logger.experiment.config.update({'batch_size': batch_size, 'epochs': trainer_config['max_epochs']})\n","        wandb_logger.watch(model)\n","\n","        # For CSV logger:\n","        csv_logger = CSVLogger(save_dir=model_folder/cl_config['log_dir'], name=cl_config['csv']['name'])\n","        csv_logger.log_hyperparams(params={'batch_size': batch_size, 'epochs': trainer_config['max_epochs']})\n","\n","        trainer = pl.Trainer(callbacks=callbacks,\n","                            logger=[csv_logger, wandb_logger],\n","                            **trainer_config)\n","    else:\n","        trainer = pl.Trainer(callbacks=callbacks,\n","                            **trainer_config\n","                )\n","    return trainer\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2fQcAqoVCliR"},"source":["# Function to load components"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"YCM2UWkrCliS","executionInfo":{"status":"ok","timestamp":1697592869630,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def load_components(model_config, data_module_config, lightning_module_config, data_folder, trainer_config,\n","cl_config, batch_size,logging=False, checkpointing=True, early_stopping=False):\n","\n","    # Load the model\n","    model = load_model(model_config)\n","\n","    # Load the data module\n","    dm = load_datamodule(data_module_config, data_folder)\n","\n","    # Load the lightning module\n","    lightning_module = load_lightning_module(lightning_module_config, model)\n","\n","    # Load the trainer\n","    trainer = load_trainer(model, trainer_config, cl_config, batch_size, model_folder,  logging=logging,\n","                           checkpointing=checkpointing, early_stopping=early_stopping)\n","\n","    return model, dm, lightning_module, trainer"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Zx3vaIJ6CliS","executionInfo":{"status":"ok","timestamp":1697592869631,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def load_yaml(filepath):\n","    with open(filepath, 'r') as file:\n","        return yaml.safe_load(file)"]},{"cell_type":"markdown","metadata":{"id":"B04nRTbJCliS"},"source":["# Function to Load config files"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6zpwkbsxCliS","executionInfo":{"status":"ok","timestamp":1697592869631,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["# Load configurations from YAML files\n","def load_all_configs():\n","    model_config = load_yaml(project_folder/'model_config.yaml')\n","    data_module_config = load_yaml(project_folder/'data_module_config.yaml')\n","    lightning_module_config = load_yaml(project_folder/'lightning_module_config.yaml')\n","    cl_config = load_yaml(project_folder/'callbacks_loggers_config.yaml')\n","    trainer_config = load_yaml(project_folder/'trainer_config.yaml')\n","\n","    return model_config, data_module_config, lightning_module_config, cl_config, trainer_config\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TEsf1RtfCliS"},"source":["# Function to free memory"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bL969siJCliS","executionInfo":{"status":"ok","timestamp":1697592869631,"user_tz":300,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["def free_memory():\n","    \"\"\"\n","    Attempts to free up memory by deleting variables and running Python's garbage collector.\n","    \"\"\"\n","    gc.collect()\n","    for device_id in range(torch.cuda.device_count()):\n","        torch.cuda.set_device(device_id)\n","        torch.cuda.empty_cache()\n","    gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"9R29vVCMCliS"},"source":["# Run One training and validation batch to check bugs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":1926,"status":"error","timestamp":1697592871551,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"Rby6Gf18CliT","outputId":"287cc05d-62ac-460a-bda5-835b15a70b06"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b2a5653d8453>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfree_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning_module_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# override default values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fast_dev_run'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-bc48fd8c76b1>\u001b[0m in \u001b[0;36mload_all_configs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load configurations from YAML files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_all_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'model_config.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata_module_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'data_module_config.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlightning_module_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'lightning_module_config.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-b66a0b62cc2e>\u001b[0m in \u001b[0;36mload_yaml\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab_Notebooks/BUAN_6382_Applied_DeepLearning/Data/data/imagenette2/model_config.yaml'"]}],"source":["# Load components\n","free_memory()\n","seed_everything(42)\n","model_config, data_module_config, lightning_module_config, cl_config, trainer_config = load_all_configs()\n","# override default values\n","trainer_config['fast_dev_run']=True\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=False, checkpointing=False, early_stopping=False)\n","dm.prepare_data()\n","trainer.fit(lightning_module, dm)"]},{"cell_type":"markdown","metadata":{"id":"dqHcyZ-UCliT"},"source":["# Find Learning Rate"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1697592871552,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"6BOKUXtwCliT"},"outputs":[],"source":["# Load components\n","free_memory()\n","seed_everything(42)\n","model_config, data_module_config, lightning_module_config, cl_config, trainer_config = load_all_configs()\n","# override default values\n","trainer_config['max_epochs']=5\n","data_module_config['data_module']['batch_size']=64\n","\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=False, checkpointing=False, early_stopping=False)\n","dm.setup()\n","tuner = Tuner(trainer)\n","lr_finder = tuner.lr_find(lightning_module, datamodule=dm, min_lr=1e-5, max_lr=1, num_training=30, mode='exponential')\n","fig = lr_finder.plot(suggest=True)\n","new_lr = lr_finder.suggestion()\n","print(new_lr)\n"]},{"cell_type":"markdown","metadata":{"id":"FNIzeydkCliT"},"source":["# Overfit Small Subset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1697592871552,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"eyJsv4ZQCliT"},"outputs":[],"source":["# Load components\n","\n","free_memory()\n","seed_everything(42)\n","model_config, data_module_config, lightning_module_config, cl_config, trainer_config = load_all_configs()\n","\n","# override default values\n","data_module_config['data_module']['batch_size']=128\n","trainer_config['overfit_batches']=1\n","lightning_module_config['others']['learning_rate']=0.007\n","trainer_config['max_epochs']=3\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=False, checkpointing=False, early_stopping=False)\n","dm.setup()\n","trainer.fit(lightning_module, dm)"]},{"cell_type":"markdown","metadata":{"id":"4vgrxKBJCliT"},"source":["# Regularization -I\n","- Early stopping with a patience of 5, total epochs = 50\n","- Gradient Clipping\n","- Weight Deacay of 1\n","- Reduce Learning rate on plateau\n","- Use 50% of train/val data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1697592871552,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"IIPS4243CliT"},"outputs":[],"source":["free_memory()\n","seed_everything(42)\n","model_config, data_module_config, lightning_module_config, cl_config, trainer_config = load_all_configs()\n","\n","# override default values\n","data_module_config['data_module']['batch_size']=128\n","lightning_module_config['others']['learning_rate']=0.007\n","trainer_config['max_epochs']=50\n","trainer_config['gradient_clip_val']=2\n","trainer_config['log_every_n_steps']=20\n","\n","lightning_module_config['others']['optimizer_params']['weight_decay']=1\n","lightning_module_config['others']['learning_rate']=0.007\n","lightning_module_config['scheduler_cls']='torch.optim.lr_scheduler.ReduceLROnPlateau'\n","lightning_module_config['scheduler_params']= {'mode': 'max', 'patience': 0, 'factor': 0.5, 'verbose': True}\n","lightning_module_config['scheduler_options']= {'monitor': 'val_metric', 'interval': 'epoch', 'frequency': 1}\n","cl_config['lr_monitor']['logging_interval']='epoch'\n","cl_config['wandb']['project']='imagenette2_multiclass'\n","cl_config['wandb']['name']='two_layer_mlp_bn_v0'\n","\n","data_module_config['data_module']['small_subset']=True\n","data_module_config['data_module']['num_samples_small']=0.5\n","\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=True, checkpointing=True, early_stopping=True)\n","dm.setup()\n","trainer.fit(lightning_module, dm)\n","file = f\"{trainer.logger.log_dir}/metrics.csv\"\n","plot_losses_acc(file)\n","ckpt_path = trainer.checkpoint_callback.best_model_path\n","train_acc = trainer.validate(dataloaders=dm.train_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","valid_acc = trainer.validate(dataloaders=dm.val_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","print(f\"Train Accuracy: {train_acc[0]['val_metric']*100:0.2f}\")\n","print(f\"Validation Accuracy: {valid_acc[0]['val_metric']*100:0.2f}\")\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"COCtOtnLCliU"},"source":["# Regularization -II\n","- Increase the weight decay to 10"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1697592871552,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"b7rsS627CliU"},"outputs":[],"source":["lightning_module_config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBuLLBzXCliU","executionInfo":{"status":"aborted","timestamp":1697592871552,"user_tz":300,"elapsed":4,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["lightning_module_config['others']['optimizer_params']['weight_decay']=10"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1697592871553,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"vtNqkeVUCliU"},"outputs":[],"source":["lightning_module_config"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1697592871553,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":300},"id":"Y9m3Br52CliU"},"outputs":[],"source":["# Regularization -II\n","free_memory()\n","seed_everything(42)\n","\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=True, checkpointing=True, early_stopping=True)\n","dm.setup()\n","trainer.fit(lightning_module, dm)\n","file = f\"{trainer.logger.log_dir}/metrics.csv\"\n","plot_losses_acc(file)\n","ckpt_path = trainer.checkpoint_callback.best_model_path\n","train_acc = trainer.validate(dataloaders=dm.train_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","valid_acc = trainer.validate(dataloaders=dm.val_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","print(f\"Train Accuracy: {train_acc[0]['val_metric']*100:0.2f}\")\n","print(f\"Validation Accuracy: {valid_acc[0]['val_metric']*100:0.2f}\")\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"p6x0MTfjNK7C"},"source":["# HW5 PART A - Complete Regularization -III and IV"]},{"cell_type":"markdown","metadata":{"id":"oiQXwvDsCliU"},"source":["# Regularization -III\n","- Use one Cycle Learning Rate instead of Reduce Learning Rate on Plateau"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQdpuC6gD_Hi","executionInfo":{"status":"aborted","timestamp":1697592871553,"user_tz":300,"elapsed":4,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["free_memory()\n","seed_everything(42)\n","\n","\n","model_config, data_module_config, lightning_module_config, cl_config, trainer_config = load_all_configs()\n","\n","# override default values\n","data_module_config['data_module']['batch_size']=128\n","lightning_module_config['others']['learning_rate']=0.007\n","trainer_config['gradient_clip_val']=2\n","trainer_config['log_every_n_steps']=20\n","trainer_config['max_epochs']=10\n","\n","lightning_module_config['others']['optimizer_params']['weight_decay']=10\n","\n","\n","# Setting the scheduler class\n","lightning_module_config['scheduler_cls'] = # CODE HERE\n","\n","# Parameters for the OneCycleLR\n","# Note: 'max_lr' is a required parameter for OneCycleLR; you'll need to specify it based on your needs\n","lightning_module_config['scheduler_params'] = # CODE HERE\n","\n","# Options related to the monitoring of the scheduler (if needed)\n","lightning_module_config['scheduler_options'] = # CODE HERE\n","\n","\n","\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=True, checkpointing=True, early_stopping=False) # change here\n","dm.prepare_data()\n","\n","trainer.fit(lightning_module, dm)\n","file = f\"{trainer.logger.log_dir}/metrics.csv\"\n","plot_losses_acc(file)\n","ckpt_path = trainer.checkpoint_callback.best_model_path\n","train_acc = trainer.validate(dataloaders=dm.train_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","valid_acc = trainer.validate(dataloaders=dm.val_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","print(f\"Train Accuracy: {train_acc[0]['val_metric']*100:0.2f}\")\n","print(f\"Validation Accuracy: {valid_acc[0]['val_metric']*100:0.2f}\")\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"eyAGWr7mDX4g"},"source":["# Regularization-1V\n","- Use one Step LR instead of One Cycler LR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GewKpnbNDpVn","executionInfo":{"status":"aborted","timestamp":1697592871553,"user_tz":300,"elapsed":4,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}}},"outputs":[],"source":["free_memory()\n","seed_everything(42)\n","\n","model_config, data_module_config, lightning_module_config, cl_config, trainer_config = load_all_configs()\n","\n","# override default values\n","data_module_config['data_module']['batch_size']=128\n","lightning_module_config['others']['learning_rate']=0.007\n","trainer_config['gradient_clip_val']=2\n","trainer_config['log_every_n_steps']=20\n","trainer_config['max_epochs']=10\n","\n","lightning_module_config['others']['optimizer_params']['weight_decay']=10\n","\n","\n","# Setting the scheduler class\n","lightning_module_config['scheduler_cls'] = # CODE HERE\n","\n","# Parameters for the OneCycleLR\n","# Note: 'max_lr' is a required parameter for OneCycleLR; you'll need to specify it based on your needs\n","lightning_module_config['scheduler_params'] = # CODE HERE\n","\n","# Options related to the monitoring of the scheduler (if needed)\n","lightning_module_config['scheduler_options'] = # CODE HERE\n","\n","\n","\n","model, dm, lightning_module, trainer = load_components(model_config, data_module_config,\n","                                                       lightning_module_config, data_folder, trainer_config,\n","                                                        cl_config, batch_size=data_module_config['data_module']['batch_size'],\n","                                                        logging=True, checkpointing=True, early_stopping=False) # change here\n","dm.prepare_data()\n","\n","trainer.fit(lightning_module, dm)\n","file = f\"{trainer.logger.log_dir}/metrics.csv\"\n","plot_losses_acc(file)\n","ckpt_path = trainer.checkpoint_callback.best_model_path\n","train_acc = trainer.validate(dataloaders=dm.train_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","valid_acc = trainer.validate(dataloaders=dm.val_dataloader(), ckpt_path=ckpt_path, verbose=False)\n","print(f\"Train Accuracy: {train_acc[0]['val_metric']*100:0.2f}\")\n","print(f\"Validation Accuracy: {valid_acc[0]['val_metric']*100:0.2f}\")\n","wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}